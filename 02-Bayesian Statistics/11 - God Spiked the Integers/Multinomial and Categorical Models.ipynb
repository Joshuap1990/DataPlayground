{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial and Categorical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.special import expit as logistic\n",
    "from scipy.special import softmax\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "RANDOM_SEED = 8927\n",
    "np.random.seed(286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use(\"arviz-darkgrid\")\n",
    "az.rcParams[\"stats.credible_interval\"] = 0.89\n",
    "\n",
    "\n",
    "def standardize(series):\n",
    "    \"\"\"Standardize a pandas series\"\"\"\n",
    "    return (series - series.mean()) / series.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial distribution is relevant when there are only two things that can happen, and we count those things. In general, more than two things can happen. For example, recall the bag of marbles from may back in ch2.  It contained only blue and white marbles, but suppose we introduced red marbles as well. Now each draw from the bag can be one of three categories, and the count that accumulates is across all three categories.\n",
    "\n",
    "When more than two types of unordered events are possible, and the probablity of each type of event is constant across trials, then the maximum entropy distribution is the MULTINOMIAL DISTRIBUTION.\n",
    "\n",
    "A model built on a nultinomial distribution may also be called a CATEGORICAL regression, usually when each event is isolated on a single row, like with logistic regression. In machine learning this model type is sometimes known as the MAXIMUM ENTROPY CLASSIFIER\n",
    "\n",
    "The conventional and natural link in this context is the MULTINOMIAL LOGIT, aso known as the SOFTMAX function. This link function takes a vector of scores, one or each K event types, and computer the probability of a particular type of event k.\n",
    "\n",
    "Combined with this conventional link, his type of GLM may be called MULTINOMIAL LOGISTIC REGRESSION. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Predictors matched to outcomes\n",
    "\n",
    "For example, suppose you are modelling choice of career for a number of young adults. One of the relevat predictor variables is expected income. In that case, the same parameter B_income appears in each linear model, in order to estimate the impact of the income trait on the probability a career is chosen. But a different income value multiplies the parameter in each linear model.\n",
    "\n",
    "The code below simulates career choice from three different careers, each with its own income trait. These traists are used to assign a score to each type of event. Then when the model is fit to data, one of this scores is held constant, and the other two scores are estimated, using the known income traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2]),\n",
       " array([0.5, 1. , 2.5]),\n",
       " array([0.09962365, 0.16425163, 0.73612472]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate career choices among 500 individuals\n",
    "N = 500  # number of individuals\n",
    "income = np.array([1, 2, 5])  # expected income of each career\n",
    "score = 0.5 * income  # score for each career, based on income\n",
    "# converts scores to probabilities:\n",
    "p = softmax(score)\n",
    "\n",
    "# now simulate choice\n",
    "# outcome career holds event type values, not counts\n",
    "career = np.random.multinomial(1, p, size=N)\n",
    "career = np.where(career == 1)[1]\n",
    "career[:11], score, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
